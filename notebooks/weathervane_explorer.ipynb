{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from importlib import reload\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "import requests\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import zcode.inout as zio\n",
    "import zcode.math as zmath\n",
    "import zcode.plot as zplot\n",
    "\n",
    "import kalepy as kale\n",
    "\n",
    "import weathervane as wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_STATION_DATA = \"/Users/lzkelley/Programs/weathervane/data/stations\"\n",
    "\n",
    "FNAME_RAW_HISTORY = \"/Users/lzkelley/Programs/weathervane/data/raw/isd-history.csv\"\n",
    "FNAME_STATIONS = \"/Users/lzkelley/Programs/weathervane/data/us-stations_filtered.csv\"\n",
    "FNAME_INVENTORY = \"/Users/lzkelley/Programs/weathervane/data/raw/isd-inventory.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sci_not(val, **kwargs):\n",
    "    kwargs.setdefault('man', 1)\n",
    "    kwargs.setdefault('dollar', False)\n",
    "    kwargs.setdefault('sign', True)\n",
    "    return zplot.scientific_notation(val, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a subset of weather stations, save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(FNAME_RAW_HISTORY)\n",
    "# print(df.keys(), \"\\n\", df.size)\n",
    "\n",
    "# country = df['CTRY']\n",
    "# beg = df['BEGIN']\n",
    "# end = df['END']\n",
    "# state = df['STATE']\n",
    "# idx = (country == 'US') & (end > 20200000) & (beg < 20000000) & (~state.isnull())\n",
    "# print(np.count_nonzero(idx))\n",
    "\n",
    "# stations = df.loc[idx]\n",
    "# # df_filt = df_filt.sort_values('STATE')\n",
    "\n",
    "# stations.to_csv(FNAME_STATIONS, index_label='global index')\n",
    "# print(f\"Saved to {FNAME_STATIONS}, size {zio.get_file_size(FNAME_STATIONS)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations = wv.load_stations_list()\n",
    "reload(wv)\n",
    "reload(wv.main)\n",
    "reload(wv)\n",
    "stations = wv.Stations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(0)\n",
    "stations.nearest('santa cruz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 'Inventory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inventory = pd.read_csv(FNAME_INVENTORY)\n",
    "# print(f\"Loaded {inventory.size} entries from '{FNAME_INVENTORY}'\\n\\tkeys={inventory.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data for all city-matching stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = wv.Cities()\n",
    "dists = np.zeros(cities.size)\n",
    "indices = np.zeros_like(dists, dtype=int)\n",
    "for ii, (city, state) in enumerate(zio.tqdm(cities, total=cities.size, desc='cities', leave=True)):\n",
    "    name = city + \", \" + state\n",
    "    stat, idx, dd = stations.nearest(name, warn_above=None)\n",
    "    dists[ii] = dd\n",
    "    indices[ii] = idx\n",
    "    wv.download_station(stat, warn_404=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data for target station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = stations['STATION NAME'].str.contains(r'san', case=False)\n",
    "# print(idx)\n",
    "# stations.loc[19688]\n",
    "\n",
    "idx = stations['STATION NAME'].str.contains(r'chicago', case=False)\n",
    "stations.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_call = \"KSFO\"\n",
    "station_call = \"KORD\"\n",
    "stat = wv.get_station(call=station_call)\n",
    "wv.download_station(stat)\n",
    "data = wv.load_station_data(stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_conv(df_vals):\n",
    "    # df_vals = df['TMP']\n",
    "    # Convert from object array to 1D np.array of 7-char strings\n",
    "    temp = df_vals.to_numpy().astype('S7')\n",
    "    # Convert to 2D array of characters\n",
    "    temp = temp.view(dtype='S1').reshape(temp.size, len(temp[0]))\n",
    "    # Get quality code\n",
    "    qq = temp[:, 6]   # .view(np.uint8) - ord('0')\n",
    "    # Get sign\n",
    "    ss = temp[:, 0]\n",
    "    # convert to integers, combine, convert to float temperature    \n",
    "    temp = temp[:, 1:5].view(np.uint8) - ord('0')\n",
    "    aa = np.array([1000, 100, 10, 1])\n",
    "    temp = np.sum(temp * aa[np.newaxis, :], axis=1) / 10.0\n",
    "    # Add back sign\n",
    "    temp = temp * (1 + -2 * (np.array(ss) == b'-'))\n",
    "    \n",
    "    return temp, qq\n",
    "\n",
    "\n",
    "def station_to_grid(data, tzone='US/Pacific'):\n",
    "    raw_temp, qq = temp_conv(data['TMP'])\n",
    "    sel = (qq == b'1') | (qq == b'5')  # | (qq != )\n",
    "    logging.info(f\"valid temperatures = {zmath.frac_str(sel)}\")\n",
    "\n",
    "    # ---- Make sure that data starts and ends at year boundaries ----\n",
    "    time = data['DATE'].loc[sel]\n",
    "    beg_year = int(time.iloc[0].year)\n",
    "    last = time.size - 1\n",
    "    end_year = time.iloc[-1].year\n",
    "    logging.info(f\"beg date: {time.iloc[0]}, year: {beg_year}\")\n",
    "    logging.info(f\"end date: {time.iloc[last]}, year: {end_year}\")\n",
    "\n",
    "    beg = pd.Timestamp(f'{beg_year}-01-01T01:30:00', tz=tzone)\n",
    "    if time.iloc[0] >= beg:\n",
    "        beg = pd.Timestamp(f'{beg_year+1}-01-01T00:00:00', tz=tzone)\n",
    "        sel = sel & (data['DATE'] >= beg)\n",
    "    \n",
    "    end = pd.Timestamp(f'{end_year}-12-31T22:30:00', tz=tzone)\n",
    "    if time.iloc[last] <= end:\n",
    "        end = pd.Timestamp(f'{end_year}-01-01T00:00:00', tz=tzone)\n",
    "        sel = sel & (data['DATE'] < end)\n",
    "\n",
    "    logging.info(f\"valid temps and dates = {zmath.frac_str(sel)}\")\n",
    "    data = data.loc[sel]\n",
    "    raw_temp = raw_temp[sel]\n",
    "    time = data['DATE']\n",
    "\n",
    "    # Make sure it worked\n",
    "    last = time.size - 1\n",
    "    beg_year = time.iloc[0].year\n",
    "    if (time.iloc[0].day != 1) or (time.iloc[0].month != 1):\n",
    "        raise ValueError(f\"Dataset does not start on Jan. 1st!!  ({time[0]})\")\n",
    "\n",
    "    # Convert to proper timezone\n",
    "    time = time.dt.tz_convert(tzone)\n",
    "    \n",
    "    # Determine the number of complete years covered\n",
    "    nyrs = (time.iloc[last] - time.iloc[0]).total_seconds() / (3600*24*365)\n",
    "    nyrs = int(np.floor(nyrs))\n",
    "    logging.info(f\"{beg_year=}, {time.iloc[0]}, {time.iloc[last]}, {nyrs=}\")\n",
    "    \n",
    "    # ---- Find mapping of entries to target grid points ----\n",
    "    \n",
    "    # Initialize storage array, and create grid of hours after 'Jan. 1st' each year\n",
    "    index = -1 * np.ones((nyrs, 365, 24), dtype=int)\n",
    "    global_index = -1 * np.ones((nyrs, 365, 24), dtype=int)\n",
    "\n",
    "    dt_grid = np.arange(365*24).astype(float)\n",
    "\n",
    "    # Iterate over years, find the indices of entries matching each offset for that year\n",
    "    years = -1 * np.ones(nyrs, dtype=int)\n",
    "    for yy in tqdm.trange(nyrs):\n",
    "        year = beg_year + yy\n",
    "        beg = pd.Timestamp(f'{year}-01-01', tz=tzone)\n",
    "        end = pd.Timestamp(f'{year}-12-31T23:59:59', tz=tzone)\n",
    "\n",
    "        # Find the entries for this year\n",
    "        idx = (time >= beg) & (time <= end)\n",
    "        # Determine the offset (index) for the first value\n",
    "        offset = np.argmax(idx)\n",
    "        num_year = np.count_nonzero(idx)\n",
    "        epd = num_year / 365.0\n",
    "        msg = f\"{year=}, {offset=}, #/day={epd:.2f}\"\n",
    "        logging.debug(msg)\n",
    "        if epd < 1.0:\n",
    "            logging.error(msg)\n",
    "            err = f\"Entries per day is {epd:.2e} < 1!!\"\n",
    "            logging.error(err)\n",
    "            # raise ValueError(err)\n",
    "            continue\n",
    "            \n",
    "        years[yy] = year\n",
    "        \n",
    "        # Find the time of each entry relative to 'Jan 1st', in hours\n",
    "        dt = (time[idx] - beg).dt.total_seconds() / 3600.0\n",
    "        # Find the nearest entry matching each target grid-point\n",
    "        sel = zmath.argnearest(dt, dt_grid, assume_sorted=True)\n",
    "        # Store values\n",
    "        index[yy, ...].flat = offset + sel\n",
    "        \n",
    "    # ---- Select valid years ----\n",
    "    valid = (years > 0)\n",
    "    if not np.all(valid):\n",
    "        logging.warning(f\"Valid years: {zmath.frac_str(valid)}\")\n",
    "        years = years[valid]\n",
    "        index = index[valid, ...]\n",
    "        global_index = global_index[valid, ...]        \n",
    "        \n",
    "    # ---- Interpolate ----\n",
    "    \n",
    "    temp = np.zeros_like(index, dtype=float)\n",
    "    idx = index.flatten()\n",
    "    temp.flat = raw_temp[idx]\n",
    "    global_index.flat = data.iloc[idx].index.to_numpy()\n",
    "    \n",
    "    return years, temp, global_index\n",
    "\n",
    "logging.getLogger().setLevel(20)\n",
    "years, temp, gidx = station_to_grid(data);\n",
    "print(temp.shape, zmath.stats_str(temp))\n",
    "# noise = np.clip(np.random.normal(scale=0.5, size=temp.shape), -1.5, +1.5)\n",
    "# temp = sp.constants.convert_temperature(temp, 'Celsius', 'Fahrenheit') + noise\n",
    "temp = sp.constants.convert_temperature(temp, 'Celsius', 'Fahrenheit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tave = np.mean(temp, axis=0)\n",
    "levels = zmath.spacing(tave/10, scale='lin', integers=True) * 10\n",
    "print(levels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[16, 6])\n",
    "pcm = ax.pcolormesh(tave.T)\n",
    "cbar = plt.colorbar(pcm, label='Temperature [F]')\n",
    "\n",
    "ax.axhline(12, color='0.5', ls='--')\n",
    "\n",
    "edges = [np.arange(365), np.arange(24)]\n",
    "*_, cc = kale.plot.draw_contour2d(\n",
    "    ax, edges, tave, cmap=pcm.cmap.reversed(),\n",
    "    levels=levels, smooth=3, upsample=2, pad=2, cbar=cbar\n",
    ")\n",
    "\n",
    "ax.set(xlim=[0, 365], xlabel='Day of Year', ylim=[0, 24], ylabel='Hour of Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levels = [50, 60, 65]\n",
    "levels = None\n",
    "\n",
    "nyr, nday, nhr = temp.shape\n",
    "td_ave = np.mean(temp, axis=-1).T\n",
    "edges = [np.arange(nday), years]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[16, 6])\n",
    "pcm = ax.pcolormesh(*edges, td_ave.T, shading='auto')\n",
    "cbar = plt.colorbar(pcm, label='Ave Temperature [F]')\n",
    "\n",
    "*_, cc = kale.plot.draw_contour2d(\n",
    "    ax, edges, td_ave,\n",
    "    levels=levels, smooth=3, upsample=2, pad=2, cbar=cbar\n",
    ")\n",
    "\n",
    "ax.set(xlim=[0, nday], xlabel='Day of Year', ylim=zmath.minmax(years), ylabel='Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = zplot.figax(ncols=2, scale='lin', sharey=True)\n",
    "confs = [50, 90]\n",
    "\n",
    "shp = temp.shape\n",
    "\n",
    "def plot_ave_axis(ax, temp, axis):\n",
    "    test = np.moveaxis(temp, axis, 0).reshape(shp[axis], -1)\n",
    "    tave = test.mean(axis=-1)\n",
    "    hh, = ax.plot(tave)\n",
    "\n",
    "    for pp in confs:\n",
    "        conf = np.percentile(test, [50-pp/2, 50+pp/2], axis=-1)\n",
    "        ax.fill_between(np.arange(tave.shape[0]), *conf, alpha=0.2, color=hh.get_color())\n",
    "\n",
    "    return\n",
    "\n",
    "plot_ave_axis(axes[0], temp, 1)\n",
    "plot_ave_axis(axes[1], temp, 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = [20, 40]\n",
    "\n",
    "plt.figure(figsize=[12, 4])\n",
    "plt.grid(alpha=0.2)\n",
    "\n",
    "test = temp.reshape(np.shape(temp)[0], -1)\n",
    "tyr_ave = np.mean(test, axis=-1)\n",
    "tyr_med = np.median(test, axis=-1)\n",
    "# xx = np.arange(test.shape[0])\n",
    "xx = years\n",
    "\n",
    "ave_coeff, ave_fit = zmath.numeric.regress(xx, tyr_ave)\n",
    "\n",
    "hh, = plt.plot(xx, tyr_ave, ls=':', label='ave')\n",
    "col = hh.get_color()\n",
    "plt.plot(xx, tyr_med, color=col, ls='--', label='med')\n",
    "plt.plot(xx, ave_fit, color=col, ls='-', label='ave fit')\n",
    "plt.title(fr'${sci_not(ave_coeff[0])} \\; \\mathrm{{deg/yr}}$')\n",
    "\n",
    "for pp in confs:\n",
    "    conf = np.percentile(test, [50-pp/2, 50+pp/2], axis=-1)\n",
    "    plt.fill_between(xx, *conf, alpha=0.2, label=fr'${pp}\\%$', color=col)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape\n",
    "xx = years[:, np.newaxis, np.newaxis] * np.ones_like(temp)\n",
    "\n",
    "coeff, zz = zmath.numeric.regress(xx, temp)\n",
    "slope = coeff[0]\n",
    "\n",
    "levels = None\n",
    "# levels = zmath.spacing(tave/10, scale='lin', integers=True) * 10\n",
    "# print(levels)\n",
    "# levels = [-0.01, 0.01]\n",
    "\n",
    "smap = zplot.smap(slope, cmap='RdBu_r', midpoint=0.0)\n",
    "cmap = smap.cmap\n",
    "# cmap = 'RdBu_r'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[16, 6])\n",
    "pcm = ax.pcolormesh(slope.T, cmap=smap.cmap, norm=smap.norm)\n",
    "cbar = plt.colorbar(pcm, label=r'$\\Delta$ Temperature [F/yr]')\n",
    "\n",
    "ax.axhline(12, color='0.5', ls='--')\n",
    "\n",
    "edges = [np.arange(365), np.arange(24)]\n",
    "*_, cc = kale.plot.draw_contour2d(\n",
    "    ax, edges, slope, cmap=pcm.cmap.reversed(),\n",
    "    levels=levels, smooth=3, upsample=2, pad=2, cbar=cbar\n",
    ")\n",
    "\n",
    "ax.set(xlim=[0, 365], xlabel='Day of Year', ylim=[0, 24], ylabel='Hour of Day')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.shape)\n",
    "tave = np.mean(temp, axis=-1)\n",
    "xx = years[:, np.newaxis] * np.ones_like(tave)\n",
    "\n",
    "coeff, zz = zmath.numeric.regress(xx, tave)\n",
    "slope = coeff[0]\n",
    "print(slope.shape)\n",
    "\n",
    "plt.plot(slope)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = zplot.figax(ncols=2, scale='lin', sharey=True)\n",
    "confs = [50, 90]\n",
    "\n",
    "shp = temp.shape\n",
    "\n",
    "def plot_ave_axis(ax, years, temp, axis, smap=None):\n",
    "    other = 2 if (axis == 1) else 1\n",
    "    xlab = 'day of year' if (axis == 1) else 'hour of day'\n",
    "    tave = np.mean(temp, axis=other)\n",
    "\n",
    "    xx = years[:, np.newaxis] * np.ones_like(tave)\n",
    "    slope, zz = zmath.numeric.regress(xx, tave)\n",
    "    slope = slope[0]\n",
    "    if smap is None:\n",
    "        smap = zplot.smap(slope, scale='lin', cmap='RdBu_r', midpoint=0.0)\n",
    "    colors = smap.to_rgba(slope)\n",
    "    \n",
    "    test = np.moveaxis(temp, axis, 0).reshape(shp[axis], -1)\n",
    "    tave = test.mean(axis=-1)\n",
    "    xx = np.arange(tave.size)\n",
    "\n",
    "    hh, = ax.plot(xx, tave)\n",
    "    ax.scatter(xx, tave, color=colors)\n",
    "\n",
    "    for pp in confs:\n",
    "        conf = np.percentile(test, [50-pp/2, 50+pp/2], axis=-1)\n",
    "        ax.fill_between(xx, *conf, alpha=0.2, color=hh.get_color())\n",
    "\n",
    "    plt.colorbar(smap, ax=ax, orientation='horizontal', label=r'$\\Delta T$ [deg/yr]')\n",
    "    ax.set(xlabel=xlab, ylabel='Temperature [F]')\n",
    "    \n",
    "    return smap\n",
    "\n",
    "plot_ave_axis(axes[0], years, temp, 1)\n",
    "plot_ave_axis(axes[1], years, temp, 2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs = df['DATE'].dt.hour + df['DATE'].dt.minute/60 + df['DATE'].dt.second/3600\n",
    "hrs = hrs.to_numpy()\n",
    "\n",
    "days = df['DATE'].dt.dayofyear.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = df['DATE'] - df['DATE'][0]\n",
    "dt = np.diff(dt.dt.total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[18, 6])\n",
    "kale.dist1d(dt[::100]/3600, probability=True, density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hrs, bins=24*10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = 'RH1'\n",
    "df[kk][~df[kk].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kk in df.keys():\n",
    "    print(kk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of US cities by population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(wv)\n",
    "reload(wv.main)\n",
    "reload(wv)\n",
    "cities = wv.Cities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNAME_CITIES = \"/Users/lzkelley/Programs/weathervane/data/raw/SUB-IP-EST2019-ANNRNK.xlsx\"\n",
    "names = [\"rank\", \"geographic area\", \"2010 census\", \"2010 estimates base\",]\n",
    "names = names + [str(yy) for yy in range(2010, 2020)]\n",
    "# print(names)\n",
    "header = list(range(3))\n",
    "footer = list(range(792, 800))\n",
    "df = pd.read_excel(FNAME_CITIES, names=names, skiprows=header + footer)\n",
    "print(df.keys(), \"\\n\", df.size)\n",
    "# df['geographic area']\n",
    "df[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
